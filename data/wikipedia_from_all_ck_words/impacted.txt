evaluation is a systematic determination of a subject's merit worth and significance using criteria governed by a set of standards it can assist an organization program project or any other intervention or initiative to assess any aim realisable concept/proposal or any alternative to help in decision-making or to ascertain the degree of achievement or value in regard to the aim and objectives and results of any such action that has been completed the primary purpose of evaluation in addition to gaining insight into prior or existing initiatives is to enable reflection and assist in the identification of future change
evaluation is often used to characterize and appraise subjects of interest in a wide range of human enterprises including the arts criminal justice foundations non-profit organizations government health care and other human services
== definition ==
evaluation is the structured interpretation and giving of meaning to predicted or actual impacts of proposals or results it looks at original objectives and at what is either predicted or what was accomplished and how it was accomplished so evaluation can be formative that is taking place during the development of a concept or proposal project or organization with the intention of improving the value or effectiveness of the proposal project or organisation it can also be assumptive drawing lessons from a completed action or project or an organisation at a later point in time or circumstance
evaluation is inherently a theoretically informed approach (whether explicitly or not) and consequently any particular definition of evaluation would have be tailored to its context the theory needs purpose and methodology of the evaluation process itself having said this evaluation has been defined as
a systematic rigorous and meticulous application of scientific methods to assess the design implementation improvement or outcomes of a program it is a resource-intensive process frequently requiring resources such as evaluate expertise labor time and a sizable budget
the critical assessment in as objective a manner as possible of the degree to which a service or its component parts fulfills stated goals (st leger and wordsworth-bell) the focus of this definition is on attaining objective knowledge and scientifically or quantitatively measuring predetermined and external concepts
a study designed to assist some audience to assess an object's merit and worth (shuffleboard) in this definition the focus is on facts as well as value laden judgments of the programs outcomes and worth
=== purpose ===
the main purpose of a program evaluation can be to determine the quality of a program by formulating a judgment marthe hurteau sylvain houle stphanie mongiat (2009)
an alternative view is that projects evaluators and other stakeholders (including funders) will all have potentially different ideas about how best to evaluate a project since each may have a different definition of merit the core of the problem is thus about defining what is of value. from this perspective evaluation is a contested term as evaluators use the term evaluation to describe an assessment or investigation of a program whilst others simply understand evaluation as being synonymous with applied research
there are two function considering to the evaluation purpose formative evaluations provide the information on the improving a product or a process summative evaluations provide information of short-term effectiveness or long-term impact to deciding the adoption of a product or process
not all evaluations serve the same purpose some evaluations serve a monitoring function rather than focusing solely on measurable program outcomes or evaluation findings and a full list of types of evaluations would be difficult to compile this is because evaluation is not part of a unified theoretical framework drawing on a number of disciplines which include management and organisational theory policy analysis education sociology social anthropology and social change
=== discussion ===
however the strict adherence to a set of methodological assumptions may make the field of evaluation more acceptable to a mainstream audience but this adherence will work towards preventing evaluators from developing new strategies for dealing with the myriad problems that programs face
it is claimed that only a minority of evaluation reports are used by the evaluand (client) (datta 2006) one justification of this is that when evaluation findings are challenged or utilization has failed it was because stakeholders and clients found the inferences weak or the warrants unconvincing (fournier and smith 1993) some reasons for this situation may be the failure of the evaluator to establish a set of shared aims with the evaluand or creating overly ambitious aims as well as failing to compromise and incorporate the cultural differences of individuals and programs within the evaluation aims and process
none of these problems are due to a lack of a definition of evaluation but are rather due to evaluators attempting to impose predisposed notions and definitions of evaluations on clients the central reason for the poor utilization of evaluations is arguably due to the lack of tailoring of evaluations to suit the needs of the client due to a predefined idea (or definition) of what an evaluation is rather than what the client needs are (house 1980)
the development of a standard methodology for evaluation will require arriving at applicable ways of asking and stating the results of questions about ethics such as agent-principal privacy stakeholder definition limited liability and could-the-money-be-spent-more-wisely issues
== standards ==
depending on the topic of interest there are professional groups that review the quality and rigor of evaluation processes
evaluating programs and projects regarding their value and impact within the context they are implemented can be ethically challenging evaluators may encounter complex culturally specific systems resistant to external evaluation furthermore the project organization or other stakeholders may be invested in a particular evaluation outcome finally evaluators themselves may encounter conflict of interest (coi) issues or experience interference or pressure to present findings that support a particular assessment
general professional codes of conduct as determined by the employing organization usually cover three broad aspects of behavioral standards and include inter-collegial relations (such as respect for diversity and privacy) operational issues (due competence documentation accuracy and appropriate use of resources) and conflicts of interest (nepotism accepting gifts and other kinds of favoritism) however specific guidelines particular to the evaluator's role that can be utilized in the management of unique ethical challenges are required the joint committee on standards for educational evaluation has developed standards for program personnel and student evaluation the joint committee standards are broken into four sections utility feasibility propriety and accuracy various european institutions have also prepared their own standards more or less related to those produced by the joint committee they provide guidelines about basing value judgments on systematic inquiry evaluator competence and integrity respect for people and regard for the general and public welfare
the american evaluation association has created a set of guiding principles for evaluators the order of these principles does not imply priority among them priority will vary by situation and evaluator role the principles run as follows
systematic inquiry evaluators conduct systematic data-based inquiries about whatever is being evaluated this requires quality data collection including a defensible choice of indicators which lends credibility to findings findings are credible when they are demonstrably evidence-based reliable and valid this also pertains to the choice of methodology employed such that it is consistent with the aims of the evaluation and provides dependable data furthermore utility of findings is critical such that the information obtained by evaluation is comprehensive and timely and thus serves to provide maximal benefit and use to stakeholders
competence evaluators provide competent performance to stakeholders this requires that evaluation teams comprise an appropriate combination of competencies such that varied and appropriate expertise is available for the evaluation process and that evaluators work within their scope of capability
integrity/honesty evaluators ensure the honesty and integrity of the entire evaluation process a key element of this principle is freedom from bias in evaluation and this is underscored by three principles impartiality independence and transparency
independence is attained through ensuring independence of judgment is upheld such that evaluation conclusions are not influenced or pressured by another party and avoidance of conflict of interest such that the evaluator does not have a stake in a particular conclusion conflict of interest is at issue particularly where funding of evaluations is provided by particular bodies with a stake in conclusions of the evaluation and this is seen as potentially compromising the independence of the evaluator whilst it is acknowledged that evaluators may be familiar with agencies or projects that they are required to evaluate independence requires that they not have been involved in the planning or implementation of the project a declaration of interest should be made where any benefits or association with project are stated independence of judgment is required to be maintained against any pressures brought to bear on evaluators for example by project funders wishing to modify evaluations such that the project appears more effective than
findings can verify
impartiality pertains to findings being a fair and thorough assessment of strengths and weaknesses of a project or program this requires taking due input from all stakeholders involved and findings presented without bias and with a transparent proportionate and persuasive link between findings and recommendations thus evaluators are required to delimit their findings to evidence a mechanism to ensure impartiality is external and internal review such review is required of significant (determined in terms of cost or sensitivity) evaluations the review is based on quality of work and the degree to which a demonstrable link is provided between findings
and recommendations
transparency requires that stakeholders are aware of the reason for the evaluation the criteria by which evaluation occurs and the purposes to which the findings will be applied access to the evaluation document should be facilitated through findings being easily readable with clear explanations of evaluation methodologies approaches sources of information and costs
incurred
respect for people evaluators respect the security dignity and self-worth of the respondents program participants clients and other stakeholders with whom they interact.this is particularly pertinent with regards to those who will be impacted upon by the evaluation findings protection of people includes ensuring informed consent from those involved in the evaluation upholding confidentiality and ensuring that the identity of those who may provide sensitive information towards the program evaluation is protected evaluators are ethically required to respect the customs and beliefs of those who are impacted upon by the evaluation or program activities examples of how such respect is demonstrated is through respecting local customs e.g dress codes respecting peoples privacy and minimizing demands on others time where stakeholders wish to place objections to evaluation findings such a process should be facilitated through the local office of the evaluation organization and procedures for lodging complaints or queries should be accessible and clear
responsibilities for general and public welfare evaluators articulate and take into account the diversity of interests and values that may be related to the general and public welfare access to evaluation documents by the wider public should be facilitated such that discussion and feedback is enabled
furthermore the international organizations such as the i.m.f and the world bank have independent evaluation functions the various funds programmes and agencies of the united nations has a mix of independent semi-independent and self-evaluation functions which have organized themselves as a system-wide un evaluation group (uneg) that works together to strengthen the function and to establish un norms and standards for evaluation there is also an evaluation group within the oecd-dac which endeavors to improve development evaluation standards the independent evaluation units of the major multinational development banks (mdbs) have also created the evaluation cooperation group to strengthen the use of evaluation for greater mdb effectiveness and accountability share lessons from mdb evaluations and promote evaluation harmonization and collaboration
== perspectives of evaluation ==
the word evaluation has various connotations for different people raising issues related to this process that include what type of evaluation should be conducted why there should be an evaluation process and how the evaluation is integrated into a program for the purpose of gaining greater knowledge and awareness
there are also various factors inherent in the evaluation process for example to critically examine influences within a program that involve the gathering and analyzing of relative information about a program michael quinn patton motivated the concept that the evaluation procedure should be directed towards
activities
characteristics
outcomes
the making of judgments on a program
improving its effectiveness
informed programming decisions
founded on another perspective of evaluation by thomson and hoffman in 2003 it is possible for a situation to be encountered in which the process could not be considered advisable for instance in the event of a program being unpredictable or unsound this would include it lacking a consistent routine or the concerned parties unable to reach an agreement regarding the purpose of the program in addition an influencer or manager refusing to incorporate relevant important central issues within the evaluation
== approaches ==
evaluation approaches are conceptually distinct ways of thinking about designing and conducting evaluation efforts many of the evaluation approaches in use today make truly unique contributions to solving important problems while others refine existing approaches in some way
=== classification of approaches ===
two classifications of evaluation approaches by house and stufflebeam and webster can be combined into a manageable number of approaches in terms of their unique and important underlying principles
house considers all major evaluation approaches to be based on a common ideology entitled liberal democracy important principles of this ideology include freedom of choice the uniqueness of the individual and empirical inquiry grounded in objectivity he also contends that they are all based on subjectivist ethics in which ethical conduct is based on the subjective or intuitive experience of an individual or group one form of subjectivist ethics is utilitarian in which the good is determined by what maximizes a single explicit interpretation of happiness for society as a whole another form of subjectivist ethics is intuitionist/pluralist in which no single interpretation of the good is assumed and such interpretations need not be explicitly stated nor justified
these ethical positions have corresponding epistemologiesphilosophies for obtaining knowledge the objectivist epistemology is associated with the utilitarian ethic in general it is used to acquire knowledge that can be externally verified (intersubjective agreement) through publicly exposed methods and data the subjectivist epistemology is associated with the intuitionist/pluralist ethic and is used to acquire new knowledge based on existing personal knowledge as well as experiences that are (explicit) or are not (tacit) available for public inspection house then divides each epistemological approach into two main political perspectives firstly approaches can take an elite perspective focusing on the interests of managers and professionals or they also can take a mass perspective focusing on consumers and participatory approaches
stufflebeam and webster place approaches into one of three groups according to their orientation toward the role of values and ethical consideration the political orientation promotes a positive or negative view of an object regardless of what its value actually is and might bethey call this pseudo-evaluation the questions orientation includes approaches that might or might not provide answers specifically related to the value of an objectthey call this quasi-evaluation the values orientation includes approaches primarily intended to determine the value of an objectthey call this true evaluation
when the above concepts are considered simultaneously fifteen evaluation approaches can be identified in terms of epistemology major perspective (from house) and orientation two pseudo-evaluation approaches politically controlled and public relations studies are represented they are based on an objectivist epistemology from an elite perspective six quasi-evaluation approaches use an objectivist epistemology five of themexperimental research management information systems testing programs objectives-based studies and content analysistake an elite perspective accountability takes a mass perspective seven true evaluation approaches are included two approaches decision-oriented and policy studies are based on an objectivist epistemology from an elite perspective consumer-oriented studies are based on an objectivist epistemology from a mass perspective two approachesaccreditation/certification and connoisseur studiesare based on a subjectivist epistemology from an elite perspective finally adversary and client-centered studies are based on a subjectivist epistemology from a mass perspective
=== summary of approaches ===
the following table is used to summarize each approach in terms of four attributesorganizer purpose strengths and weaknesses the organizer represents the main considerations or cues practitioners use to organize a study the purpose represents the desired outcome for a study at a very general level strengths and weaknesses represent other attributes that should be considered when deciding whether to use the approach for a particular study the following narrative highlights differences between approaches grouped together
=== pseudo-evaluation ===
politically controlled and public relations studies are based on an objectivist epistemology from an elite perspective although both of these approaches seek to misrepresent value interpretations about an object they function differently from each other information obtained through politically controlled studies is released or withheld to meet the special interests of the holder whereas public relations information creates a positive image of an object regardless of the actual situation despite the application of both studies in real scenarios neither of these approaches is acceptable evaluation practice
=== objectivist elite quasi-evaluation ===
as a group these five approaches represent a highly respected collection of disciplined inquiry approaches they are considered quasi-evaluation approaches because particular studies legitimately can focus only on questions of knowledge without addressing any questions of value such studies are by definition not evaluations these approaches can produce characterizations without producing appraisals although specific studies can produce both each of these approaches serves its intended purpose well they are discussed roughly in order of the extent to which they approach the objectivist ideal
experimental research is the best approach for determining causal relationships between variables the potential problem with using this as an evaluation approach is that its highly controlled and stylized methodology may not be sufficiently responsive to the dynamically changing needs of most human service programs
management information systems (miss) can give detailed information about the dynamic operations of complex programs however this information is restricted to readily quantifiable data usually available at regular intervals
testing programs are familiar to just about anyone who has attended school served in the military or worked for a large company these programs are good at comparing individuals or groups to selected norms in a number of subject areas or to a set of standards of performance however they only focus on testee performance and they might not adequately sample what is taught or expected
objectives-based approaches relate outcomes to prespecified objectives allowing judgments to be made about their level of attainment unfortunately the objectives are often not proven to be important or they focus on outcomes too narrow to provide the basis for determining the value of an object
content analysis is a quasi-evaluation approach because content analysis judgments need not be based on value statements instead they can be based on knowledge such content analyses are not evaluations on the other hand when content analysis judgments are based on values such studies are evaluations
=== objectivist mass quasi-evaluation ===
accountability is popular with constituents because it is intended to provide an accurate accounting of results that can improve the quality of products and services however this approach quickly can turn practitioners and consumers into adversaries when implemented in a heavy-handed fashion
objectivist elite true evaluation
decision-oriented studies are designed to provide a knowledge base for making and defending decisions this approach usually requires the close collaboration between an evaluator and decision-maker allowing it to be susceptible to corruption and bias
policy studies provide general guidance and direction on broad issues by identifying and assessing potential costs and benefits of competing policies the drawback is these studies can be corrupted or subverted by the politically motivated actions of the participants
=== objectivist mass true evaluation ===
consumer-oriented studies are used to judge the relative merits of goods and services based on generalized needs and values along with a comprehensive range of effects however this approach does not necessarily help practitioners improve their work and it requires a very good and credible evaluator to do it well
=== subjectivist elite true evaluation ===
accreditation / certification programs are based on self-study and peer review of organizations programs and personnel they draw on the insights experience and expertise of qualified individuals who use established guidelines to determine if the applicant should be approved to perform specified functions however unless performance-based standards are used attributes of applicants and the processes they perform often are overemphasized in relation to measures of outcomes or effects
connoisseur studies use the highly refined skills of individuals intimately familiar with the subject of the evaluation to critically characterize and appraise it this approach can help others see programs in a new light but it is difficult to find a qualified and unbiased connoisseur
=== subjectivist mass true evaluation ===
the adversary approach focuses on drawing out the pros and cons of controversial issues through quasi-legal proceedings this helps ensure a balanced presentation of different perspectives on the issues but it is also likely to discourage later cooperation and heighten animosities between contesting parties if winners and losers emerge
=== client-centered ===
client-centered studies address specific concerns and issues of practitioners and other clients of the study in a particular setting these studies help people understand the activities and values involved from a variety of perspectives however this responsive approach can lead to low external credibility and a favorable bias toward those who participated in the study
== methods and techniques ==
evaluation is methodologically diverse methods may be qualitative or quantitative and include case studies survey research statistical analysis model building and many more such as
== see also ==
monitoring and evaluation is a process used by governments international organizations and ngos to assess ongoing or past activities
assessment is the process of gathering and analyzing specific information as part of an evaluation
competency evaluation is a means for teachers to determine the ability of their students in other ways besides the standardized test
educational evaluation is evaluation that is conducted specifically in an educational setting
immanent evaluation opposed by gilles deleuze to value judgment
performance evaluation is a term from the field of language testing it stands in contrast to competence evaluation
program evaluation is essentially a set of philosophies and techniques to determine if a program works
donald kirkpatrick's evaluation model for training evaluation
== references ==
== external links ==
links to assessment and evaluation resources - list of links to resources on several topics
glossaries
evaluation portal link collection evaluation link collection with information about evaluation journals dissemination projects societies how-to texts books and much more
free resources for methods in evaluation and social research
introduction to and discussions on monitoring & evaluation of development programs & projects
