{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we will run lda on the whole wiki sample and ck12\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                line = unicode(line, encoding='utf-8', errors='replace')\n",
    "                yield line.split()\n",
    "                \n",
    "                \n",
    "path = '/Users/MK/GitHub/the_answer_is/data/temporary4'\n",
    "sentences = MySentences(path)\n",
    "\n",
    "dictionary = corpora.Dictionary(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define stopwords \n",
    "stoplist = [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours',\n",
    "             u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', \n",
    "             u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', \n",
    "             u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', \n",
    "             u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', \n",
    "             u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', \n",
    "             u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', \n",
    "             u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', \n",
    "             u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', \n",
    "             u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', \n",
    "             u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', \n",
    "             u'should', u'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior to removing words that only appear once:\n",
      "Dictionary(394 unique tokens: [u'essay', u'influenza', u'founder', u'lack', u'abil']...)\n",
      "after removing: \n",
      "Dictionary(101 unique tokens: [u'influenza', u'reservoir', u'less', u'endem', u'cold']...)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print 'prior to removing words that only appear once:'\n",
    "print dictionary\n",
    "#remove infrequent words in the dictionary\n",
    "#remove stopwords in the dictionary\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
    "dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
    "dictionary\n",
    "print 'after removing: '\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'influenza': 0, u'reservoir': 1, u'less': 2, u'endem': 3, u'cold': 4, u'either': 6, u'spread': 7, u'sourc': 8, u'march': 9, u'epidem': 10, u'period': 52, u'mechan': 12, u'gate': 13, u'increas': 14, u'affect': 15, u'requir': 16, u'introduct': 17, u'term': 18, u'success': 20, u'organ': 19, u'vector': 21, u'common': 22, u'refer': 23, u'mean': 24, u'respond': 25, u'vehicl': 26, u'epidemiolog': 27, u'eg': 28, u'rate': 29, u'respons': 30, u'guarante': 31, u'transmiss': 32, u'safeti': 33, u'abl': 34, u'may': 88, u'health': 36, u'condit': 37, u'pandem': 38, u'diseas': 39, u'persontoperson': 40, u'genet': 41, u'water': 42, u'host': 43, u'vertic': 44, u'popul': 45, u'materi': 70, u'contamin': 47, u'place': 48, u'mani': 49, u'chang': 50, u'undergo': 51, u'number': 11, u'one': 53, u'feet': 54, u'system': 55, u'next': 56, u'attack': 57, u'includ': 58, u'way': 59, u'time': 99, u'individu': 60, u'form': 61, u'infect': 62, u'suscept': 63, u'surveil': 64, u'case': 65, u'exposur': 66, u'novel': 67, u'prepar': 68, u'biolog': 69, u'could': 46, u'propag': 71, u'certain': 72, u'agent': 73, u'general': 74, u'say': 75, u'generat': 76, u'occur': 77, u'sever': 78, u'develop': 79, u'medic': 80, u'emerg': 98, u'take': 82, u'peopl': 83, u'transmit': 84, u'outbreak': 85, u'week': 86, u'infecti': 87, u'multipli': 35, u'worker': 89, u'drink': 90, u'two': 91, u'consid': 92, u'countri': 93, u'droplet': 94, u'short': 95, u'later': 96, u'caus': 97, u'exampl': 81, u'epi': 5, u'usual': 100}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if you do not care about the memory, just do\n",
    "# corpus = [dictionary.doc2bow(word) for word in sentences]\n",
    "\n",
    "class MyCorpus(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                line = unicode(line, encoding='utf-8', errors='replace')\n",
    "                yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "path = '/Users/MK/GitHub/the_answer_is/data/temporary4'\n",
    "corpus = MyCorpus(path)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model saving\n",
    "corpora.MmCorpus.serialize('/Users/MK/GitHub/the_answer_is/models/lda/test_corpus_saved.mm', corpus)\n",
    "#load_corpus = corpora.MmCorpus('/Users/MK/GitHub/the_answer_is/models/lda/wiki_ck_corpus_saved.mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x10809e790>\n"
     ]
    }
   ],
   "source": [
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:input corpus stream has no len(); counting documents\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.LdaModel(corpus, id2word = dictionary, num_topics=3\n",
    "                            )\n",
    "#lda = gensim.models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=100, update_every=1, chunksize=10000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.042*diseas + 0.038*outbreak + 0.034*emerg + 0.033*transmiss + 0.032*host + 0.029*exposur + 0.028*common + 0.024*sourc + 0.023*worker + 0.021*epidem'),\n",
       " (1,\n",
       "  u'0.089*epidem + 0.039*diseas + 0.028*peopl + 0.025*may + 0.023*occur + 0.023*spread + 0.021*infect + 0.019*common + 0.017*health + 0.017*outbreak'),\n",
       " (2,\n",
       "  u'0.108*transmiss + 0.055*agent + 0.032*vehicl + 0.027*develop + 0.027*contamin + 0.026*spread + 0.026*mechan + 0.026*biolog + 0.026*propag + 0.025*infect')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(102, 0.98044119860059198)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'courtesy is mapped to 3712 in the dictionary, \n",
    "# flickrbalancedcrafts is mapped to 1 in the dictionary. \n",
    "# if we have a document with 100 words of courtesy, and 1 word of flickrbalancedcrafts,\n",
    "# the document is represented as below, and is close to the topic 18, which contains the word coutesy with weight 0.085 \n",
    "doc_bow = [(3712, 100), (1, 1)]\n",
    "lda[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>correctAnswer</th>\n",
       "      <th>answerA</th>\n",
       "      <th>answerB</th>\n",
       "      <th>answerC</th>\n",
       "      <th>answerD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>When athletes begin to exercise, their heart r...</td>\n",
       "      <td>C</td>\n",
       "      <td>at the tissue level</td>\n",
       "      <td>at the organ level</td>\n",
       "      <td>at the system level</td>\n",
       "      <td>at the cellular level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>Which example describes a learned behavior in ...</td>\n",
       "      <td>C</td>\n",
       "      <td>smelling the air for odors</td>\n",
       "      <td>barking when disturbed</td>\n",
       "      <td>sitting on command</td>\n",
       "      <td>digging in soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>When two nuclei are combined into one nucleus,...</td>\n",
       "      <td>D</td>\n",
       "      <td>conversion</td>\n",
       "      <td>reaction</td>\n",
       "      <td>fission</td>\n",
       "      <td>fusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>Which is a distinction between an epidemic and...</td>\n",
       "      <td>B</td>\n",
       "      <td>the symptoms of the disease</td>\n",
       "      <td>the geographical area affected</td>\n",
       "      <td>the species of organisms infected</td>\n",
       "      <td>the season in which the disease spreads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>In which way is the orbit of a comet different...</td>\n",
       "      <td>B</td>\n",
       "      <td>The orbit of Earth is less circular than the o...</td>\n",
       "      <td>The orbit of a comet is more elliptical than t...</td>\n",
       "      <td>The orbital period of Earth is much longer tha...</td>\n",
       "      <td>The orbital period of a comet is more predicta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           question correctAnswer  \\\n",
       "0  100001  When athletes begin to exercise, their heart r...             C   \n",
       "1  100002  Which example describes a learned behavior in ...             C   \n",
       "2  100003  When two nuclei are combined into one nucleus,...             D   \n",
       "3  100004  Which is a distinction between an epidemic and...             B   \n",
       "4  100005  In which way is the orbit of a comet different...             B   \n",
       "\n",
       "                                             answerA  \\\n",
       "0                                at the tissue level   \n",
       "1                         smelling the air for odors   \n",
       "2                                         conversion   \n",
       "3                        the symptoms of the disease   \n",
       "4  The orbit of Earth is less circular than the o...   \n",
       "\n",
       "                                             answerB  \\\n",
       "0                                 at the organ level   \n",
       "1                             barking when disturbed   \n",
       "2                                           reaction   \n",
       "3                     the geographical area affected   \n",
       "4  The orbit of a comet is more elliptical than t...   \n",
       "\n",
       "                                             answerC  \\\n",
       "0                                at the system level   \n",
       "1                                 sitting on command   \n",
       "2                                            fission   \n",
       "3                  the species of organisms infected   \n",
       "4  The orbital period of Earth is much longer tha...   \n",
       "\n",
       "                                             answerD  \n",
       "0                              at the cellular level  \n",
       "1                                    digging in soil  \n",
       "2                                             fusion  \n",
       "3            the season in which the disease spreads  \n",
       "4  The orbital period of a comet is more predicta...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "path = '/Users/MK/GitHub/the_answer_is/data'\n",
    "os.chdir(path)\n",
    "train = pd.read_table('training_set.tsv',sep = '\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'two', 'nuclei', 'are', 'combined', 'into', 'one', 'nucleus,', 'there', 'is', 'a', 'slight', 'change', 'in', 'mass', 'and', 'the', 'release', 'of', 'a', 'large', 'amount', 'of', 'energy.', 'What', 'is', 'this', 'process', 'called?'] ['conversion'] ['reaction'] ['fission'] ['fusion']\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "q = train.ix[i][1].split()\n",
    "a1 = train.ix[i][3].split()\n",
    "a2 = train.ix[i][4].split()\n",
    "a3 = train.ix[i][5].split()\n",
    "a4 = train.ix[i][6].split()\n",
    "    \n",
    "print q,a1,a2,a3,a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.083749999999999811),\n",
       " (57, 0.088109974441187372),\n",
       " (59, 0.084843451326104283),\n",
       " (86, 0.20425121521302006),\n",
       " (111, 0.083749999999999811),\n",
       " (115, 0.06111558918919191),\n",
       " (148, 0.095639923595379248),\n",
       " (176, 0.1260330324061251),\n",
       " (196, 0.092923480495657115)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert question into corpus and run lda. \n",
    "corpus = dictionary.doc2bow(q)\n",
    "lda[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 57, 59, 86, 111, 115, 148, 176, 196]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexlist = [x[0] for x in lda[corpus]]\n",
    "indexlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.298*mass + 0.122*data + 0.082*smaller + 0.081*center + 0.052*mean + 0.038*images + 0.036*entire + 0.024*taxonomy + 0.020*satellites + 0.019*machine\n",
      "0.286*process + 0.170*produce + 0.067*ice + 0.039*may + 0.029*called + 0.022*rotational + 0.020*stronger + 0.018*efficient + 0.018*poor + 0.016*transported\n",
      "0.231*changes + 0.071*rock + 0.070*away + 0.057*release + 0.050*eruptions + 0.039*growing + 0.033*reduction + 0.032*estimate + 0.032*sediment + 0.030*trait\n",
      "0.125*rather + 0.062*whose + 0.060*consists + 0.052*idea + 0.049*better + 0.044*combined + 0.041*devices + 0.032*stages + 0.029*older + 0.028*access\n",
      "0.172*change + 0.130*single + 0.079*climate + 0.055*basis + 0.042*problems + 0.040*vary + 0.039*john + 0.037*social + 0.033*displacement + 0.031*resources\n",
      "0.146*given + 0.110*defined + 0.099*terms + 0.075*amount + 0.074*n + 0.061*position + 0.060*thought + 0.057*x + 0.032*completely + 0.032*respect\n",
      "0.183*could + 0.173*current + 0.081*nuclei + 0.066*isotopes + 0.050*explain + 0.045*yet + 0.039*diameter + 0.024*thomas + 0.022*von + 0.016*debate\n",
      "0.125*volume + 0.083*appear + 0.081*expressed + 0.061*done + 0.061*hand + 0.041*hours + 0.034*reactors + 0.027*ordinary + 0.023*mixtures + 0.021*may\n",
      "0.296*heat + 0.109*electric + 0.062*phenomena + 0.039*thermodynamic + 0.033*slow + 0.024*transform + 0.019*turbine + 0.018*sky + 0.017*engine + 0.016*store\n"
     ]
    }
   ],
   "source": [
    "for index in indexlist:\n",
    "    print lda.print_topic(index)\n",
    "    \n",
    "#this is the words that are in the topics which are close to the quesion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
